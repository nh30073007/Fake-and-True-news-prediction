{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53d70b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
      "1   Failed GOP Candidates Remembered In Hilarious...   \n",
      "2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n",
      "3  California AG pledges to defend birth control ...   \n",
      "4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  Donald Trump s White House is in chaos, and th...          News   \n",
      "1  Now that Donald Trump is the presumptive GOP n...          News   \n",
      "2  Mike Pence is a huge homophobe. He supports ex...          News   \n",
      "3  SAN FRANCISCO (Reuters) - California Attorney ...  politicsNews   \n",
      "4  Twisted reasoning is all that comes from Pelos...      politics   \n",
      "\n",
      "               date  label  \n",
      "0     July 21, 2017      0  \n",
      "1       May 7, 2016      0  \n",
      "2  December 3, 2016      0  \n",
      "3  October 6, 2017       1  \n",
      "4      Apr 25, 2017      0  \n"
     ]
    }
   ],
   "source": [
    "#COMBINE 2 DATASET FAKE AND TRUE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TRUE_DATASET\n",
    "true_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\True.csv\")\n",
    "\n",
    "# FAKE_DATASET\n",
    "fake_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\Fake.csv\")\n",
    "\n",
    "# LABEL 1 TRUE AND LABEL 0 FAKE\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# COMBINE DATASET\n",
    "combined_data = pd.concat([true_data, fake_data], ignore_index=True)\n",
    "\n",
    "# EXCHANGE THE COMBINE DATASET\n",
    "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71df0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca79b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bdb25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
      "1   Failed GOP Candidates Remembered In Hilarious...   \n",
      "2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n",
      "3  California AG pledges to defend birth control ...   \n",
      "4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  [donald, trump, white, house, chaos, trying, c...          News   \n",
      "1  [donald, trump, presumptive, gop, nominee, tim...          News   \n",
      "2  [mike, penny, huge, homophobe, support, exgay,...          News   \n",
      "3  [san, francisco, reuters, california, attorney...  politicsNews   \n",
      "4  [twisted, reasoning, come, pelosi, day, especi...      politics   \n",
      "\n",
      "               date  label  \n",
      "0     July 21, 2017      0  \n",
      "1       May 7, 2016      0  \n",
      "2  December 3, 2016      0  \n",
      "3  October 6, 2017       1  \n",
      "4      Apr 25, 2017      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# TRUE_DATASET\n",
    "true_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\True.csv\")\n",
    "\n",
    "# FAKE_DATASET\n",
    "fake_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\Fake.csv\")\n",
    "\n",
    "# LABEL 1 TRUE AND LABEL 0 FAKE\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# COMBINE DATASET\n",
    "combined_data = pd.concat([true_data, fake_data], ignore_index=True)\n",
    "\n",
    "# EXCHANGE THE COMBINE DATASET\n",
    "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#CONVERT TO LOWERCASE, REMOVE SPECIAL CHRACHTER, TOKENIZATION\n",
    "combined_data['text'] = combined_data['text'].str.lower() \n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))  \n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: word_tokenize(x)) \n",
    "\n",
    "\n",
    "#REMOVE STOPWORDS, LEMMATIZATION\n",
    "stop_words = set(stopwords.words('english'))\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: [word for word in x if word not in stop_words])  \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])  \n",
    "\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f0c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd32d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
      "1   Failed GOP Candidates Remembered In Hilarious...   \n",
      "2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n",
      "3  California AG pledges to defend birth control ...   \n",
      "4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0  donald trump white house chaos trying cover ru...          News   \n",
      "1  donald trump presumptive gop nominee time reme...          News   \n",
      "2  mike penny huge homophobe support exgay conver...          News   \n",
      "3  san francisco reuters california attorney gene...  politicsNews   \n",
      "4  twisted reasoning come pelosi day especially 2...      politics   \n",
      "\n",
      "               date  label    0    1    2    3    4  ...  218702  218703  \\\n",
      "0     July 21, 2017      0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "1       May 7, 2016      0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "2  December 3, 2016      0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "3  October 6, 2017       1  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "4      Apr 25, 2017      0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
      "\n",
      "   218704  218705  218706  218707  218708  218709  218710  218711  \n",
      "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 218717 columns]\n"
     ]
    }
   ],
   "source": [
    "#USED TF-IDF FEATURE \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TRUE_DATASET\n",
    "true_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\True.csv\")\n",
    "\n",
    "# FAKE_DATASET\n",
    "fake_data = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\fake and real news dataset\\Fake.csv\")\n",
    "\n",
    "# LABEL 1 TRUE AND LABEL 0 FAKE\n",
    "true_data['label'] = 1\n",
    "fake_data['label'] = 0\n",
    "\n",
    "# COMBINE DATASET\n",
    "combined_data = pd.concat([true_data, fake_data], ignore_index=True)\n",
    "\n",
    "# EXCHANGE THE COMBINE DATASET\n",
    "combined_data = combined_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# CONVERT TO LOWERCASE, REMOVE SPECIAL CHARACTERS, TOKENIZATION\n",
    "combined_data['text'] = combined_data['text'].str.lower()\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# REMOVE STOPWORDS, LEMMATIZATION\n",
    "stop_words = set(stopwords.words('english'))\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# CONVERT TOKENIZED TEXT TO STRING\n",
    "combined_data['text'] = combined_data['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(combined_data['text'])\n",
    "\n",
    "# CONCATENATE TF-IDF FEATURES WITH THE ORIGINAL DATA\n",
    "combined_data = pd.concat([combined_data, pd.DataFrame.sparse.from_spmatrix(X)], axis=1)\n",
    "\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eee215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55023d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
